{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# **Machine Learning Hackathon**\n",
    "\n",
    "## **Topic: Energy Usage Prediction System**\n",
    "    \n",
    "**Problem statement:**\n",
    "    \n",
    "Create a methodology that utilizes data to **predict the electricity consumption** of\n",
    "household appliances in low-energy homes, and **provide suggestions for optimizing\n",
    "energy usage by identifying controllable factors.**\n",
    "\n",
    "This approach will involve collecting data on various factors such as \n",
    "    a) appliance usage patterns *(data available)*, \n",
    "    b) weather conditions *(data available)*, and \n",
    "    c) other environmental factors *(data available)* \n",
    "that affect energy consumption. The data will be analyzed to determine trends and patterns that can inform recommendations for efficient energy usage.\n",
    "\n",
    "These **recommendations may include adjusting the timing of appliance usage, implementing energy-efficient appliances, and taking advantage of renewable energy sources.** *(domain knowledge required)*\n",
    "\n",
    "Ultimately, the goal is to help homeowners reduce their electricity bills and minimize\n",
    "their environmental impact by maximizing the efficient use of energy.\n",
    "\n",
    "Attribute Information:\n",
    "    \n",
    "1. date : time year-month-day hour:minute:second\n",
    "2. Appliances : energy use ( transformed data), Logarithmic value from Wh\n",
    "3. lights, energy use of light fixtures in the house in Wh\n",
    "4. T1, Temperature in kitchen area, in Celsius\n",
    "5. RH_1, Humidity in kitchen area, in %\n",
    "6. T2, Temperature in living room area, in Celsius\n",
    "7. RH_2, Humidity in living room area, in %\n",
    "8. T3, Temperature in laundry room area\n",
    "9. RH_3, Humidity in laundry room area, in %\n",
    "10. T4, Temperature in office room, in Celsius\n",
    "11. RH_4, Humidity in office room, in %\n",
    "12. T5, Temperature in bathroom, in Celsius\n",
    "13. RH_5, Humidity in bathroom, in %\n",
    "14. T6, Temperature outside the building (north side), in Celsius\n",
    "15. RH_6, Humidity outside the building (north side), in %\n",
    "16. T7, Temperature in ironing room , in Celsius\n",
    "17. RH_7, Humidity in ironing room, in %\n",
    "18. T8, Temperature in teenager room 2, in Celsius\n",
    "19. RH_8, Humidity in teenager room 2, in %\n",
    "20. T9, Temperature in parents room, in Celsius\n",
    "21. RH_9, Humidity in parents room, in %\n",
    "22. To, Temperature outside (from XYZ weather station), in Celsius\n",
    "23. Pressure (from XYZ weather station), in mm Hg\n",
    "24. RH_out, Humidity outside (from XYZ weather station), in %\n",
    "25. Wind speed (from XYZ weather station), in m/s\n",
    "26. Visibility (from XYZ weather station), in km\n",
    "27. Tdewpoint (from XYZ weather station), Â°C\n",
    "28. rv1, Random variable 1, non dimensional\n",
    "29. rv2, Random variable 2, non dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ydata-profiling\n",
      "  Obtaining dependency information for ydata-profiling from https://files.pythonhosted.org/packages/49/03/04ce11264d78f7a9f1025a13f8a078aa18eb2a9c628bc0a9a9c18673062c/ydata_profiling-4.7.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading ydata_profiling-4.7.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy<1.12,>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.11.1)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (2.0.3)\n",
      "Requirement already satisfied: matplotlib<3.9,>=3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (3.7.2)\n",
      "Collecting pydantic>=2 (from ydata-profiling)\n",
      "  Obtaining dependency information for pydantic>=2 from https://files.pythonhosted.org/packages/16/ca/330c4f3bd983bb24ac12c7fd1e08c26c8aed70bc64498cf38c770321067f/pydantic-2.7.0-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "     ---------------------------------------- 0.0/103.4 kB ? eta -:--:--\n",
      "     -------------- ---------------------- 41.0/103.4 kB 991.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 103.4/103.4 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (6.0)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (3.1.2)\n",
      "Collecting visions[type_image_path]<0.7.7,>=0.7.5 (from ydata-profiling)\n",
      "  Obtaining dependency information for visions[type_image_path]<0.7.7,>=0.7.5 from https://files.pythonhosted.org/packages/7c/bf/612b24e711ae25dea9af19b9304634b8949faa0b035fad47e8bcadf62f59/visions-0.7.6-py3-none-any.whl.metadata\n",
      "  Downloading visions-0.7.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.24.3)\n",
      "Collecting htmlmin==0.1.12 (from ydata-profiling)\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting phik<0.13,>=0.11.1 (from ydata-profiling)\n",
      "  Obtaining dependency information for phik<0.13,>=0.11.1 from https://files.pythonhosted.org/packages/95/e3/250ce99ed761389028543fcb876176ba619f6bf387d6cce3bab736bd92cc/phik-0.12.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading phik-0.12.4-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (4.65.0)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.12.2)\n",
      "Collecting multimethod<2,>=1.4 (from ydata-profiling)\n",
      "  Obtaining dependency information for multimethod<2,>=1.4 from https://files.pythonhosted.org/packages/a0/96/47dc456936530adb1360aba7300f2da2e1d277fb361e025db3926653e189/multimethod-1.11.2-py3-none-any.whl.metadata\n",
      "  Downloading multimethod-1.11.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.14.0)\n",
      "Collecting typeguard<5,>=4.1.2 (from ydata-profiling)\n",
      "  Obtaining dependency information for typeguard<5,>=4.1.2 from https://files.pythonhosted.org/packages/d9/59/e02336eb478ccdfc9bb0d4c27ce04a4260cd8b45aa04f6b00bcfdbb66a2a/typeguard-4.2.1-py3-none-any.whl.metadata\n",
      "  Downloading typeguard-4.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting imagehash==4.3.1 (from ydata-profiling)\n",
      "  Obtaining dependency information for imagehash==4.3.1 from https://files.pythonhosted.org/packages/2d/b4/19a746a986c6e38595fa5947c028b1b8e287773dcad766e648897ad2a4cf/ImageHash-4.3.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting wordcloud>=1.9.1 (from ydata-profiling)\n",
      "  Obtaining dependency information for wordcloud>=1.9.1 from https://files.pythonhosted.org/packages/f5/b0/247159f61c5d5d6647171bef84430b7efad4db504f0229674024f3a4f7f2/wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting dacite>=1.8 (from ydata-profiling)\n",
      "  Obtaining dependency information for dacite>=1.8 from https://files.pythonhosted.org/packages/21/0f/cf0943f4f55f0fbc7c6bd60caf1343061dff818b02af5a0d444e473bb78d/dacite-1.8.1-py3-none-any.whl.metadata\n",
      "  Downloading dacite-1.8.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numba<1,>=0.56.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.57.1)\n",
      "Requirement already satisfied: PyWavelets in c:\\programdata\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling) (1.4.1)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba<1,>=0.56.0->ydata-profiling) (0.40.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2023.3)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.2.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2->ydata-profiling)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic>=2->ydata-profiling)\n",
      "  Obtaining dependency information for pydantic-core==2.18.1 from https://files.pythonhosted.org/packages/65/9c/04371826c287b9e0233b2a7c910ea0275a41d6a9574e186a43ead32cd22c/pydantic_core-2.18.1-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.18.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic>=2->ydata-profiling) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (2024.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5,>=4.48.2->ydata-profiling) (0.4.6)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic>=2->ydata-profiling)\n",
      "  Obtaining dependency information for typing-extensions>=4.6.1 from https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (22.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (3.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\n",
      "Downloading ydata_profiling-4.7.0-py2.py3-none-any.whl (357 kB)\n",
      "   ---------------------------------------- 0.0/357.9 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 174.1/357.9 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 357.9/357.9 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "   ---------------------------------------- 0.0/296.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 286.7/296.5 kB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 296.5/296.5 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Downloading multimethod-1.11.2-py3-none-any.whl (10 kB)\n",
      "Downloading phik-0.12.4-cp311-cp311-win_amd64.whl (667 kB)\n",
      "   ---------------------------------------- 0.0/667.1 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 235.5/667.1 kB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 430.1/667.1 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  655.4/667.1 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 667.1/667.1 kB 4.2 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "Using cached pydantic_core-2.18.1-cp311-none-win_amd64.whl (1.9 MB)\n",
      "Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
      "Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.2 kB ? eta -:--:--\n",
      "   -------------------------------------- - 286.7/300.2 kB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 300.2/300.2 kB 4.7 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Downloading visions-0.7.6-py3-none-any.whl (104 kB)\n",
      "   ---------------------------------------- 0.0/104.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 104.8/104.8 kB 3.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27092 sha256=36686709dcf031abb1be7193b8d3c292b4a90db0e15316be5f048cb803e1e4cc\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\8d\\55\\1a\\19cd535375ed1ede0c996405ebffe34b196d78e2d9545723a2\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: htmlmin, typing-extensions, multimethod, dacite, annotated-types, typeguard, pydantic-core, imagehash, wordcloud, visions, pydantic, phik, ydata-profiling\n",
      "Successfully installed annotated-types-0.6.0 dacite-1.8.1 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.11.2 phik-0.12.4 pydantic-2.7.0 pydantic-core-2.18.1 typeguard-4.2.1 typing-extensions-4.11.0 visions-0.7.6 wordcloud-1.9.3 ydata-profiling-4.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n",
      "  WARNING: The script htmlmin.exe is installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script wordcloud_cli.exe is installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pandas_profiling.exe and ydata_profiling.exe are installed in 'C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, which is not installed.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.7.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 goals:\n",
    "\n",
    "1. Predicting Energy consumption patterns on unseen data\n",
    "2. Identifying drivers of consumption and recommending the controllable features for optimizing consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "- [1. Data Loading, Imports](#1)\n",
    "- [2. Preprocessing](#2)\n",
    "- [3. Feature Engineering,  Exploratory Data Analysis](#3)\n",
    "    >[3.1 Univariate Analysis](#3.1)\n",
    "    \n",
    "    >[3.2 Bivariate Analysis](#3.2)\n",
    "    \n",
    "    >[3.3 Multivariate Analysis](#3.3)\n",
    "    \n",
    "    >[3.4 Summary Observations and Recommendations](#3.4)\n",
    "- [4. Model Training, Hyperparameter tuning, Evaluation](#4)\n",
    "- [5. Recommendations, EDA Summary, Model Summary](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# 1. Data Loading, Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:41:44.023393Z",
     "iopub.status.busy": "2023-06-18T17:41:44.022344Z",
     "iopub.status.idle": "2023-06-18T17:41:45.240420Z",
     "shell.execute_reply": "2023-06-18T17:41:45.239299Z",
     "shell.execute_reply.started": "2023-06-18T17:41:44.023356Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set plot style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "plt.rcParams['figure.figsize']=15,8\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.pandas.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:41:47.075564Z",
     "iopub.status.busy": "2023-06-18T17:41:47.075101Z",
     "iopub.status.idle": "2023-06-18T17:41:47.210809Z",
     "shell.execute_reply": "2023-06-18T17:41:47.209176Z",
     "shell.execute_reply.started": "2023-06-18T17:41:47.075530Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv/train.csv')\n",
    "df_t = pd.read_csv('./test.csv/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframe description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:00.960066Z",
     "iopub.status.busy": "2023-06-18T17:42:00.959641Z",
     "iopub.status.idle": "2023-06-18T17:42:03.341128Z",
     "shell.execute_reply": "2023-06-18T17:42:03.339985Z",
     "shell.execute_reply.started": "2023-06-18T17:42:00.960035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (15788, 30)\n",
      "================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15788 entries, 0 to 15787\n",
      "Data columns (total 29 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ID           15788 non-null  int64  \n",
      " 1   lights       15788 non-null  int64  \n",
      " 2   t1           15788 non-null  float64\n",
      " 3   rh_1         15788 non-null  float64\n",
      " 4   t2           15788 non-null  float64\n",
      " 5   rh_2         15788 non-null  float64\n",
      " 6   t3           15788 non-null  float64\n",
      " 7   rh_3         15788 non-null  float64\n",
      " 8   t4           15788 non-null  float64\n",
      " 9   rh_4         15788 non-null  float64\n",
      " 10  t5           15788 non-null  float64\n",
      " 11  rh_5         15788 non-null  float64\n",
      " 12  t6           15788 non-null  float64\n",
      " 13  rh_6         15788 non-null  float64\n",
      " 14  t7           15788 non-null  float64\n",
      " 15  rh_7         15788 non-null  float64\n",
      " 16  t8           15788 non-null  float64\n",
      " 17  rh_8         15788 non-null  float64\n",
      " 18  t9           15788 non-null  float64\n",
      " 19  rh_9         15788 non-null  float64\n",
      " 20  t_out        15788 non-null  float64\n",
      " 21  press_mm_hg  15788 non-null  float64\n",
      " 22  rh_out       15788 non-null  float64\n",
      " 23  windspeed    15788 non-null  float64\n",
      " 24  visibility   15788 non-null  float64\n",
      " 25  tdewpoint    15788 non-null  float64\n",
      " 26  rv1          15788 non-null  float64\n",
      " 27  rv2          15788 non-null  float64\n",
      " 28  appliances   15788 non-null  float64\n",
      "dtypes: float64(27), int64(2)\n",
      "memory usage: 3.5 MB\n",
      "Information about dataset \n",
      " None \n",
      "\n",
      "================================================================================\n",
      "Null Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 0),\n",
       " ID             0\n",
       " lights         0\n",
       " t1             0\n",
       " rh_1           0\n",
       " t2             0\n",
       " rh_2           0\n",
       " t3             0\n",
       " rh_3           0\n",
       " t4             0\n",
       " rh_4           0\n",
       " t5             0\n",
       " rh_5           0\n",
       " t6             0\n",
       " rh_6           0\n",
       " t7             0\n",
       " rh_7           0\n",
       " t8             0\n",
       " rh_8           0\n",
       " t9             0\n",
       " rh_9           0\n",
       " t_out          0\n",
       " press_mm_hg    0\n",
       " rh_out         0\n",
       " windspeed      0\n",
       " visibility     0\n",
       " tdewpoint      0\n",
       " rv1            0\n",
       " rv2            0\n",
       " appliances     0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets start with the df_customer_demographic \n",
    "print('Shape:', df.shape)\n",
    "\n",
    "print('='*80)\n",
    "print('Information about dataset \\n',df.info(),'\\n')\n",
    "\n",
    "print('='*80)\n",
    "print('Null Values')\n",
    "missing_indices = set()\n",
    "for index, row in df.iterrows():\n",
    "    if row.isnull().any():\n",
    "        missing_indices.add(index)\n",
    "(len(missing_indices), df.isna().sum().sum()),df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:06.664319Z",
     "iopub.status.busy": "2023-06-18T17:42:06.663843Z",
     "iopub.status.idle": "2023-06-18T17:42:06.691057Z",
     "shell.execute_reply": "2023-06-18T17:42:06.689539Z",
     "shell.execute_reply.started": "2023-06-18T17:42:06.664282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "First 5 rows \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lights</th>\n",
       "      <th>t1</th>\n",
       "      <th>rh_1</th>\n",
       "      <th>t2</th>\n",
       "      <th>rh_2</th>\n",
       "      <th>t3</th>\n",
       "      <th>rh_3</th>\n",
       "      <th>t4</th>\n",
       "      <th>rh_4</th>\n",
       "      <th>t5</th>\n",
       "      <th>rh_5</th>\n",
       "      <th>t6</th>\n",
       "      <th>rh_6</th>\n",
       "      <th>t7</th>\n",
       "      <th>rh_7</th>\n",
       "      <th>t8</th>\n",
       "      <th>rh_8</th>\n",
       "      <th>t9</th>\n",
       "      <th>rh_9</th>\n",
       "      <th>t_out</th>\n",
       "      <th>press_mm_hg</th>\n",
       "      <th>rh_out</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>visibility</th>\n",
       "      <th>tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "      <th>appliances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2133</td>\n",
       "      <td>0</td>\n",
       "      <td>19.890</td>\n",
       "      <td>45.500</td>\n",
       "      <td>19.200</td>\n",
       "      <td>45.090</td>\n",
       "      <td>20.390</td>\n",
       "      <td>44.290</td>\n",
       "      <td>19.100</td>\n",
       "      <td>46.700</td>\n",
       "      <td>17.511</td>\n",
       "      <td>53.000</td>\n",
       "      <td>11.100</td>\n",
       "      <td>98.433</td>\n",
       "      <td>17.500</td>\n",
       "      <td>43.500</td>\n",
       "      <td>18.111</td>\n",
       "      <td>50.000</td>\n",
       "      <td>17.167</td>\n",
       "      <td>48.700</td>\n",
       "      <td>10.300</td>\n",
       "      <td>761.900</td>\n",
       "      <td>85.500</td>\n",
       "      <td>7.500</td>\n",
       "      <td>23.500</td>\n",
       "      <td>7.950</td>\n",
       "      <td>39.241</td>\n",
       "      <td>39.241</td>\n",
       "      <td>3.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19730</td>\n",
       "      <td>0</td>\n",
       "      <td>25.567</td>\n",
       "      <td>46.560</td>\n",
       "      <td>25.890</td>\n",
       "      <td>42.026</td>\n",
       "      <td>27.200</td>\n",
       "      <td>41.163</td>\n",
       "      <td>24.700</td>\n",
       "      <td>45.590</td>\n",
       "      <td>23.200</td>\n",
       "      <td>52.400</td>\n",
       "      <td>24.797</td>\n",
       "      <td>1.000</td>\n",
       "      <td>24.500</td>\n",
       "      <td>44.500</td>\n",
       "      <td>24.700</td>\n",
       "      <td>50.074</td>\n",
       "      <td>23.200</td>\n",
       "      <td>46.790</td>\n",
       "      <td>22.733</td>\n",
       "      <td>755.200</td>\n",
       "      <td>55.667</td>\n",
       "      <td>3.333</td>\n",
       "      <td>23.667</td>\n",
       "      <td>13.333</td>\n",
       "      <td>43.097</td>\n",
       "      <td>43.097</td>\n",
       "      <td>4.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3288</td>\n",
       "      <td>0</td>\n",
       "      <td>22.500</td>\n",
       "      <td>44.430</td>\n",
       "      <td>21.533</td>\n",
       "      <td>42.590</td>\n",
       "      <td>21.963</td>\n",
       "      <td>44.555</td>\n",
       "      <td>22.000</td>\n",
       "      <td>40.467</td>\n",
       "      <td>19.100</td>\n",
       "      <td>55.327</td>\n",
       "      <td>6.530</td>\n",
       "      <td>61.463</td>\n",
       "      <td>19.290</td>\n",
       "      <td>34.320</td>\n",
       "      <td>20.567</td>\n",
       "      <td>41.331</td>\n",
       "      <td>18.600</td>\n",
       "      <td>45.530</td>\n",
       "      <td>6.600</td>\n",
       "      <td>760.200</td>\n",
       "      <td>64.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>42.055</td>\n",
       "      <td>42.055</td>\n",
       "      <td>4.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7730</td>\n",
       "      <td>0</td>\n",
       "      <td>19.790</td>\n",
       "      <td>38.060</td>\n",
       "      <td>17.200</td>\n",
       "      <td>40.933</td>\n",
       "      <td>20.600</td>\n",
       "      <td>37.163</td>\n",
       "      <td>18.390</td>\n",
       "      <td>37.000</td>\n",
       "      <td>18.290</td>\n",
       "      <td>42.260</td>\n",
       "      <td>2.790</td>\n",
       "      <td>79.933</td>\n",
       "      <td>18.100</td>\n",
       "      <td>32.000</td>\n",
       "      <td>20.500</td>\n",
       "      <td>42.590</td>\n",
       "      <td>18.390</td>\n",
       "      <td>40.723</td>\n",
       "      <td>2.100</td>\n",
       "      <td>741.533</td>\n",
       "      <td>94.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>48.667</td>\n",
       "      <td>1.233</td>\n",
       "      <td>12.616</td>\n",
       "      <td>12.616</td>\n",
       "      <td>3.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8852</td>\n",
       "      <td>0</td>\n",
       "      <td>20.600</td>\n",
       "      <td>35.290</td>\n",
       "      <td>17.100</td>\n",
       "      <td>39.790</td>\n",
       "      <td>20.290</td>\n",
       "      <td>37.000</td>\n",
       "      <td>19.500</td>\n",
       "      <td>34.500</td>\n",
       "      <td>18.200</td>\n",
       "      <td>49.000</td>\n",
       "      <td>-0.667</td>\n",
       "      <td>68.530</td>\n",
       "      <td>20.700</td>\n",
       "      <td>33.590</td>\n",
       "      <td>22.700</td>\n",
       "      <td>39.260</td>\n",
       "      <td>18.927</td>\n",
       "      <td>40.090</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>768.267</td>\n",
       "      <td>92.333</td>\n",
       "      <td>1.667</td>\n",
       "      <td>34.000</td>\n",
       "      <td>-1.933</td>\n",
       "      <td>10.898</td>\n",
       "      <td>10.898</td>\n",
       "      <td>3.689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  lights     t1   rh_1     t2   rh_2     t3   rh_3     t4   rh_4  \\\n",
       "0   2133       0 19.890 45.500 19.200 45.090 20.390 44.290 19.100 46.700   \n",
       "1  19730       0 25.567 46.560 25.890 42.026 27.200 41.163 24.700 45.590   \n",
       "2   3288       0 22.500 44.430 21.533 42.590 21.963 44.555 22.000 40.467   \n",
       "3   7730       0 19.790 38.060 17.200 40.933 20.600 37.163 18.390 37.000   \n",
       "4   8852       0 20.600 35.290 17.100 39.790 20.290 37.000 19.500 34.500   \n",
       "\n",
       "      t5   rh_5     t6   rh_6     t7   rh_7     t8   rh_8     t9   rh_9  \\\n",
       "0 17.511 53.000 11.100 98.433 17.500 43.500 18.111 50.000 17.167 48.700   \n",
       "1 23.200 52.400 24.797  1.000 24.500 44.500 24.700 50.074 23.200 46.790   \n",
       "2 19.100 55.327  6.530 61.463 19.290 34.320 20.567 41.331 18.600 45.530   \n",
       "3 18.290 42.260  2.790 79.933 18.100 32.000 20.500 42.590 18.390 40.723   \n",
       "4 18.200 49.000 -0.667 68.530 20.700 33.590 22.700 39.260 18.927 40.090   \n",
       "\n",
       "   t_out  press_mm_hg  rh_out  windspeed  visibility  tdewpoint    rv1    rv2  \\\n",
       "0 10.300      761.900  85.500      7.500      23.500      7.950 39.241 39.241   \n",
       "1 22.733      755.200  55.667      3.333      23.667     13.333 43.097 43.097   \n",
       "2  6.600      760.200  64.000      8.000      40.000      0.200 42.055 42.055   \n",
       "3  2.100      741.533  94.333      1.000      48.667      1.233 12.616 12.616   \n",
       "4 -0.867      768.267  92.333      1.667      34.000     -1.933 10.898 10.898   \n",
       "\n",
       "   appliances  \n",
       "0       3.912  \n",
       "1       4.605  \n",
       "2       4.248  \n",
       "3       3.689  \n",
       "4       3.689  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('First 5 rows \\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:08.987963Z",
     "iopub.status.busy": "2023-06-18T17:42:08.987525Z",
     "iopub.status.idle": "2023-06-18T17:42:09.093806Z",
     "shell.execute_reply": "2023-06-18T17:42:09.092469Z",
     "shell.execute_reply.started": "2023-06-18T17:42:08.987929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Describe the dataset \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>lights</th>\n",
       "      <th>t1</th>\n",
       "      <th>rh_1</th>\n",
       "      <th>t2</th>\n",
       "      <th>rh_2</th>\n",
       "      <th>t3</th>\n",
       "      <th>rh_3</th>\n",
       "      <th>t4</th>\n",
       "      <th>rh_4</th>\n",
       "      <th>t5</th>\n",
       "      <th>rh_5</th>\n",
       "      <th>t6</th>\n",
       "      <th>rh_6</th>\n",
       "      <th>t7</th>\n",
       "      <th>rh_7</th>\n",
       "      <th>t8</th>\n",
       "      <th>rh_8</th>\n",
       "      <th>t9</th>\n",
       "      <th>rh_9</th>\n",
       "      <th>t_out</th>\n",
       "      <th>press_mm_hg</th>\n",
       "      <th>rh_out</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>visibility</th>\n",
       "      <th>tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "      <th>appliances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "      <td>15788.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9872.640</td>\n",
       "      <td>3.809</td>\n",
       "      <td>21.689</td>\n",
       "      <td>40.266</td>\n",
       "      <td>20.345</td>\n",
       "      <td>40.429</td>\n",
       "      <td>22.269</td>\n",
       "      <td>39.248</td>\n",
       "      <td>20.854</td>\n",
       "      <td>39.047</td>\n",
       "      <td>19.598</td>\n",
       "      <td>50.949</td>\n",
       "      <td>7.914</td>\n",
       "      <td>54.637</td>\n",
       "      <td>20.267</td>\n",
       "      <td>35.411</td>\n",
       "      <td>22.029</td>\n",
       "      <td>42.964</td>\n",
       "      <td>19.488</td>\n",
       "      <td>41.571</td>\n",
       "      <td>7.418</td>\n",
       "      <td>755.532</td>\n",
       "      <td>79.823</td>\n",
       "      <td>4.031</td>\n",
       "      <td>38.331</td>\n",
       "      <td>3.781</td>\n",
       "      <td>25.028</td>\n",
       "      <td>25.028</td>\n",
       "      <td>4.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5712.930</td>\n",
       "      <td>7.963</td>\n",
       "      <td>1.610</td>\n",
       "      <td>3.957</td>\n",
       "      <td>2.196</td>\n",
       "      <td>4.068</td>\n",
       "      <td>2.008</td>\n",
       "      <td>3.246</td>\n",
       "      <td>2.051</td>\n",
       "      <td>4.329</td>\n",
       "      <td>1.851</td>\n",
       "      <td>9.002</td>\n",
       "      <td>6.102</td>\n",
       "      <td>31.211</td>\n",
       "      <td>2.117</td>\n",
       "      <td>5.109</td>\n",
       "      <td>1.959</td>\n",
       "      <td>5.219</td>\n",
       "      <td>2.022</td>\n",
       "      <td>4.156</td>\n",
       "      <td>5.328</td>\n",
       "      <td>7.373</td>\n",
       "      <td>14.895</td>\n",
       "      <td>2.436</td>\n",
       "      <td>11.816</td>\n",
       "      <td>4.202</td>\n",
       "      <td>14.505</td>\n",
       "      <td>14.505</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.790</td>\n",
       "      <td>27.023</td>\n",
       "      <td>16.100</td>\n",
       "      <td>20.463</td>\n",
       "      <td>17.200</td>\n",
       "      <td>28.767</td>\n",
       "      <td>15.100</td>\n",
       "      <td>27.660</td>\n",
       "      <td>15.330</td>\n",
       "      <td>30.167</td>\n",
       "      <td>-6.030</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15.390</td>\n",
       "      <td>23.230</td>\n",
       "      <td>16.307</td>\n",
       "      <td>29.600</td>\n",
       "      <td>14.890</td>\n",
       "      <td>29.167</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>729.300</td>\n",
       "      <td>24.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-6.600</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4922.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.776</td>\n",
       "      <td>37.399</td>\n",
       "      <td>18.823</td>\n",
       "      <td>37.900</td>\n",
       "      <td>20.790</td>\n",
       "      <td>36.900</td>\n",
       "      <td>19.533</td>\n",
       "      <td>35.590</td>\n",
       "      <td>18.290</td>\n",
       "      <td>45.433</td>\n",
       "      <td>3.595</td>\n",
       "      <td>29.992</td>\n",
       "      <td>18.700</td>\n",
       "      <td>31.500</td>\n",
       "      <td>20.790</td>\n",
       "      <td>39.090</td>\n",
       "      <td>18.000</td>\n",
       "      <td>38.530</td>\n",
       "      <td>3.633</td>\n",
       "      <td>750.917</td>\n",
       "      <td>70.333</td>\n",
       "      <td>2.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.933</td>\n",
       "      <td>12.510</td>\n",
       "      <td>12.510</td>\n",
       "      <td>3.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9907.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.600</td>\n",
       "      <td>39.663</td>\n",
       "      <td>20.000</td>\n",
       "      <td>40.500</td>\n",
       "      <td>22.100</td>\n",
       "      <td>38.560</td>\n",
       "      <td>20.633</td>\n",
       "      <td>38.463</td>\n",
       "      <td>19.390</td>\n",
       "      <td>49.078</td>\n",
       "      <td>7.300</td>\n",
       "      <td>55.297</td>\n",
       "      <td>20.060</td>\n",
       "      <td>34.900</td>\n",
       "      <td>22.100</td>\n",
       "      <td>42.428</td>\n",
       "      <td>19.390</td>\n",
       "      <td>40.933</td>\n",
       "      <td>6.933</td>\n",
       "      <td>756.100</td>\n",
       "      <td>84.000</td>\n",
       "      <td>3.667</td>\n",
       "      <td>40.000</td>\n",
       "      <td>3.433</td>\n",
       "      <td>24.912</td>\n",
       "      <td>24.912</td>\n",
       "      <td>4.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14821.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.600</td>\n",
       "      <td>43.060</td>\n",
       "      <td>21.500</td>\n",
       "      <td>43.290</td>\n",
       "      <td>23.290</td>\n",
       "      <td>41.760</td>\n",
       "      <td>22.100</td>\n",
       "      <td>42.193</td>\n",
       "      <td>20.632</td>\n",
       "      <td>53.703</td>\n",
       "      <td>11.263</td>\n",
       "      <td>83.301</td>\n",
       "      <td>21.600</td>\n",
       "      <td>39.017</td>\n",
       "      <td>23.390</td>\n",
       "      <td>46.562</td>\n",
       "      <td>20.600</td>\n",
       "      <td>44.363</td>\n",
       "      <td>10.417</td>\n",
       "      <td>760.937</td>\n",
       "      <td>91.667</td>\n",
       "      <td>5.500</td>\n",
       "      <td>40.000</td>\n",
       "      <td>6.600</td>\n",
       "      <td>37.666</td>\n",
       "      <td>37.666</td>\n",
       "      <td>4.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19734.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>26.260</td>\n",
       "      <td>57.423</td>\n",
       "      <td>29.857</td>\n",
       "      <td>54.767</td>\n",
       "      <td>29.236</td>\n",
       "      <td>50.163</td>\n",
       "      <td>26.200</td>\n",
       "      <td>51.090</td>\n",
       "      <td>25.795</td>\n",
       "      <td>96.322</td>\n",
       "      <td>28.290</td>\n",
       "      <td>99.900</td>\n",
       "      <td>25.963</td>\n",
       "      <td>51.328</td>\n",
       "      <td>27.230</td>\n",
       "      <td>58.780</td>\n",
       "      <td>24.500</td>\n",
       "      <td>53.327</td>\n",
       "      <td>26.100</td>\n",
       "      <td>772.300</td>\n",
       "      <td>100.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>15.400</td>\n",
       "      <td>49.997</td>\n",
       "      <td>49.997</td>\n",
       "      <td>6.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID    lights        t1      rh_1        t2      rh_2        t3  \\\n",
       "count 15788.000 15788.000 15788.000 15788.000 15788.000 15788.000 15788.000   \n",
       "mean   9872.640     3.809    21.689    40.266    20.345    40.429    22.269   \n",
       "std    5712.930     7.963     1.610     3.957     2.196     4.068     2.008   \n",
       "min       1.000     0.000    16.790    27.023    16.100    20.463    17.200   \n",
       "25%    4922.750     0.000    20.776    37.399    18.823    37.900    20.790   \n",
       "50%    9907.500     0.000    21.600    39.663    20.000    40.500    22.100   \n",
       "75%   14821.250     0.000    22.600    43.060    21.500    43.290    23.290   \n",
       "max   19734.000    70.000    26.260    57.423    29.857    54.767    29.236   \n",
       "\n",
       "           rh_3        t4      rh_4        t5      rh_5        t6      rh_6  \\\n",
       "count 15788.000 15788.000 15788.000 15788.000 15788.000 15788.000 15788.000   \n",
       "mean     39.248    20.854    39.047    19.598    50.949     7.914    54.637   \n",
       "std       3.246     2.051     4.329     1.851     9.002     6.102    31.211   \n",
       "min      28.767    15.100    27.660    15.330    30.167    -6.030     1.000   \n",
       "25%      36.900    19.533    35.590    18.290    45.433     3.595    29.992   \n",
       "50%      38.560    20.633    38.463    19.390    49.078     7.300    55.297   \n",
       "75%      41.760    22.100    42.193    20.632    53.703    11.263    83.301   \n",
       "max      50.163    26.200    51.090    25.795    96.322    28.290    99.900   \n",
       "\n",
       "             t7      rh_7        t8      rh_8        t9      rh_9     t_out  \\\n",
       "count 15788.000 15788.000 15788.000 15788.000 15788.000 15788.000 15788.000   \n",
       "mean     20.267    35.411    22.029    42.964    19.488    41.571     7.418   \n",
       "std       2.117     5.109     1.959     5.219     2.022     4.156     5.328   \n",
       "min      15.390    23.230    16.307    29.600    14.890    29.167    -5.000   \n",
       "25%      18.700    31.500    20.790    39.090    18.000    38.530     3.633   \n",
       "50%      20.060    34.900    22.100    42.428    19.390    40.933     6.933   \n",
       "75%      21.600    39.017    23.390    46.562    20.600    44.363    10.417   \n",
       "max      25.963    51.328    27.230    58.780    24.500    53.327    26.100   \n",
       "\n",
       "       press_mm_hg    rh_out  windspeed  visibility  tdewpoint       rv1  \\\n",
       "count    15788.000 15788.000  15788.000   15788.000  15788.000 15788.000   \n",
       "mean       755.532    79.823      4.031      38.331      3.781    25.028   \n",
       "std          7.373    14.895      2.436      11.816      4.202    14.505   \n",
       "min        729.300    24.000      0.000       1.000     -6.600     0.006   \n",
       "25%        750.917    70.333      2.000      29.000      0.933    12.510   \n",
       "50%        756.100    84.000      3.667      40.000      3.433    24.912   \n",
       "75%        760.937    91.667      5.500      40.000      6.600    37.666   \n",
       "max        772.300   100.000     14.000      66.000     15.400    49.997   \n",
       "\n",
       "            rv2  appliances  \n",
       "count 15788.000   15788.000  \n",
       "mean     25.028       4.305  \n",
       "std      14.505       0.657  \n",
       "min       0.006       2.303  \n",
       "25%      12.510       3.912  \n",
       "50%      24.912       4.094  \n",
       "75%      37.666       4.605  \n",
       "max      49.997       6.985  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('Describe the dataset \\n')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:12.639576Z",
     "iopub.status.busy": "2023-06-18T17:42:12.639193Z",
     "iopub.status.idle": "2023-06-18T17:42:12.669997Z",
     "shell.execute_reply": "2023-06-18T17:42:12.668515Z",
     "shell.execute_reply.started": "2023-06-18T17:42:12.639540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates count:\t 0\n"
     ]
    }
   ],
   "source": [
    "print('Duplicates count:\\t',df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier Analysis and Handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:14.400506Z",
     "iopub.status.busy": "2023-06-18T17:42:14.400037Z",
     "iopub.status.idle": "2023-06-18T17:42:14.430782Z",
     "shell.execute_reply": "2023-06-18T17:42:14.429446Z",
     "shell.execute_reply.started": "2023-06-18T17:42:14.400473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Skewness \n",
      " ================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID            -0.006\n",
       "lights         2.206\n",
       "t1             0.115\n",
       "rh_1           0.448\n",
       "t2             0.890\n",
       "rh_2          -0.264\n",
       "t3             0.444\n",
       "rh_3           0.464\n",
       "t4             0.166\n",
       "rh_4           0.437\n",
       "t5             0.550\n",
       "rh_5           1.881\n",
       "t6             0.597\n",
       "rh_6          -0.243\n",
       "t7             0.248\n",
       "rh_7           0.238\n",
       "t8            -0.257\n",
       "rh_8           0.304\n",
       "t9             0.375\n",
       "rh_9           0.361\n",
       "t_out          0.531\n",
       "press_mm_hg   -0.408\n",
       "rh_out        -0.920\n",
       "windspeed      0.852\n",
       "visibility     0.433\n",
       "tdewpoint      0.239\n",
       "rv1            0.005\n",
       "rv2            0.005\n",
       "appliances     1.178\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking for skewness/outliers\n",
    "print('Feature Skewness \\n','='*80)\n",
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:17.445205Z",
     "iopub.status.busy": "2023-06-18T17:42:17.444760Z",
     "iopub.status.idle": "2023-06-18T17:42:17.502131Z",
     "shell.execute_reply": "2023-06-18T17:42:17.500683Z",
     "shell.execute_reply.started": "2023-06-18T17:42:17.445170Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m outlier_row_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m      4\u001b[0m outlier_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], axis \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      6\u001b[0m     z_scores \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mzscore(df[column])\n\u001b[0;32m      7\u001b[0m     outlier_row_indices\u001b[38;5;241m.\u001b[39mupdate(np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39mabs(z_scores) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['date'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "## Let's identify outliers, beyond 2 standard deviations from feature means\n",
    "outlier_row_indices = set()\n",
    "outlier_features = dict()\n",
    "for column in df.drop(['ID','date'], axis =1).columns:\n",
    "    z_scores = stats.zscore(df[column])\n",
    "    outlier_row_indices.update(np.where(np.abs(z_scores) > 3)[0])\n",
    "    outlier_features[column]=len(np.where(np.abs(z_scores) > 3)[0])\n",
    "    \n",
    "print('No ofrows with outlier attributes:\\t',len(outlier_row_indices))\n",
    "print('Percentage of rows with outlier attributes in dataset:',len(outlier_row_indices)/ df.shape[0])\n",
    "print('\\n', '='*80)\n",
    "print('Feature wise outlier counts')\n",
    "outlier_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on psychrometric charts, features relative humidity is defined for a particular tempratre and hence t1-t9 and rh_1 to rh_9 are pair wise not correlated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:20.635811Z",
     "iopub.status.busy": "2023-06-18T17:42:20.635431Z",
     "iopub.status.idle": "2023-06-18T17:42:27.286494Z",
     "shell.execute_reply": "2023-06-18T17:42:27.285507Z",
     "shell.execute_reply.started": "2023-06-18T17:42:20.635782Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).drop('ID', axis = 1).drop('lights', axis = 1).drop('appliances', axis = 1).columns.tolist()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=20, ncols=4, figsize=(12, 50))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, variable in enumerate(numerical_columns):\n",
    "    sns.boxplot(x=df[variable], ax=axes[i]) \n",
    "    axes[i].set_title(variable) \n",
    "#     plt.savefig(f'boxplot-{variable}.jpg')\n",
    "    \n",
    "if len(numerical_columns) < len(axes):\n",
    "    for j in range(len(numerical_columns), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"3\"></a>\n",
    "# 3. Feature Engineering,  Exploratory Data Analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-17T08:15:46.035643Z",
     "iopub.status.busy": "2023-06-17T08:15:46.035302Z",
     "iopub.status.idle": "2023-06-17T08:15:46.039948Z",
     "shell.execute_reply": "2023-06-17T08:15:46.038936Z",
     "shell.execute_reply.started": "2023-06-17T08:15:46.035616Z"
    }
   },
   "source": [
    "**Reformat timestamp feature and extract date, month, week, day, hour**\n",
    "- df\n",
    "- df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:31.823721Z",
     "iopub.status.busy": "2023-06-18T17:42:31.823239Z",
     "iopub.status.idle": "2023-06-18T17:42:31.938880Z",
     "shell.execute_reply": "2023-06-18T17:42:31.937613Z",
     "shell.execute_reply.started": "2023-06-18T17:42:31.823679Z"
    }
   },
   "outputs": [],
   "source": [
    "## df\n",
    "df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "df['date_2'] = pd.to_datetime(df['date']).dt.date\n",
    "df['time'] = pd.to_datetime(df['date']).dt.time\n",
    "df['week'] = pd.to_datetime(df['date']).dt.week\n",
    "df['day_num'] = pd.to_datetime(df['date']).dt.dayofweek\n",
    "df['time'] = pd.to_datetime(df['date']).dt.time\n",
    "df['day_type'] = pd.to_datetime(df['date']).dt.dayofweek.apply(lambda x: '0' if x < 5 else '1')\n",
    "df['week_num'] = pd.to_datetime(df['date']).dt.week\n",
    "\n",
    "df[\"hour\"] = pd.to_datetime(df[\"date\"]).dt.hour\n",
    "df[\"weekday\"] = pd.to_datetime(df[\"date\"]).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:34.384256Z",
     "iopub.status.busy": "2023-06-18T17:42:34.383789Z",
     "iopub.status.idle": "2023-06-18T17:42:34.433366Z",
     "shell.execute_reply": "2023-06-18T17:42:34.432036Z",
     "shell.execute_reply.started": "2023-06-18T17:42:34.384219Z"
    }
   },
   "outputs": [],
   "source": [
    "## df_t\n",
    "df_t['month'] = pd.to_datetime(df_t['date']).dt.month\n",
    "df_t['date_2'] = pd.to_datetime(df_t['date']).dt.date\n",
    "df_t['time'] = pd.to_datetime(df_t['date']).dt.time\n",
    "df_t['week'] = pd.to_datetime(df_t['date']).dt.week\n",
    "df_t['day_num'] = pd.to_datetime(df_t['date']).dt.dayofweek\n",
    "df_t['time'] = pd.to_datetime(df_t['date']).dt.time\n",
    "df_t['day_type'] = pd.to_datetime(df_t['date']).dt.dayofweek.apply(lambda x: '0' if x < 5 else '1')\n",
    "df_t['week_num'] = pd.to_datetime(df_t['date']).dt.week\n",
    "\n",
    "df_t[\"hour\"] = pd.to_datetime(df_t[\"date\"]).dt.hour\n",
    "df_t[\"weekday\"] = pd.to_datetime(df_t[\"date\"]).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:40.088114Z",
     "iopub.status.busy": "2023-06-18T17:42:40.087477Z",
     "iopub.status.idle": "2023-06-18T17:42:40.095497Z",
     "shell.execute_reply": "2023-06-18T17:42:40.094051Z",
     "shell.execute_reply.started": "2023-06-18T17:42:40.087851Z"
    }
   },
   "outputs": [],
   "source": [
    "col_temp = [\"t1\",\"t2\",\"t3\",\"t4\",\"t5\",\"t6\",\"t7\",\"t8\",\"t9\"]\n",
    "\n",
    "col_hum = [\"rh_1\",\"rh_2\",\"rh_3\",\"rh_4\",\"rh_5\",\"rh_6\",\"rh_7\",\"rh_8\",\"rh_9\"]\n",
    "\n",
    "col_weather = [\"t_out\", \"tdewpoint\",\"rh_out\",\"press_mm_hg\",\n",
    "                \"windspeed\",\"visibility\"] \n",
    "col_light = [\"lights\"]\n",
    "\n",
    "col_randoms = [\"rv1\", \"rv2\"]\n",
    "\n",
    "col_time = [\"hour\", \"weekday\"]\n",
    "\n",
    "col_target = [\"appliances\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:43.278514Z",
     "iopub.status.busy": "2023-06-18T17:42:43.277177Z",
     "iopub.status.idle": "2023-06-18T17:42:43.297304Z",
     "shell.execute_reply": "2023-06-18T17:42:43.295566Z",
     "shell.execute_reply.started": "2023-06-18T17:42:43.278440Z"
    }
   },
   "outputs": [],
   "source": [
    "df[['day_num']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "## 3.1 Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets understand feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:48.066399Z",
     "iopub.status.busy": "2023-06-18T17:42:48.065957Z",
     "iopub.status.idle": "2023-06-18T17:42:48.074658Z",
     "shell.execute_reply": "2023-06-18T17:42:48.073296Z",
     "shell.execute_reply.started": "2023-06-18T17:42:48.066365Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:49.495226Z",
     "iopub.status.busy": "2023-06-18T17:42:49.493985Z",
     "iopub.status.idle": "2023-06-18T17:42:49.504733Z",
     "shell.execute_reply": "2023-06-18T17:42:49.502815Z",
     "shell.execute_reply.started": "2023-06-18T17:42:49.495147Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:42:53.944720Z",
     "iopub.status.busy": "2023-06-18T17:42:53.944255Z",
     "iopub.status.idle": "2023-06-18T17:43:01.540110Z",
     "shell.execute_reply": "2023-06-18T17:43:01.538848Z",
     "shell.execute_reply.started": "2023-06-18T17:42:53.944682Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).drop(['ID','month','rv1','rv2','visibility', 'windspeed',\n",
    "       'week','day_num', 'week_num', 'lights'], axis = 1).columns.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 20))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, variable in enumerate(numerical_columns):\n",
    "    df[variable].hist(ax=axes[i])\n",
    "    axes[i].set_title(variable) \n",
    "    \n",
    "fig.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:43:07.998545Z",
     "iopub.status.busy": "2023-06-18T17:43:07.998019Z",
     "iopub.status.idle": "2023-06-18T17:43:08.017247Z",
     "shell.execute_reply": "2023-06-18T17:43:08.015641Z",
     "shell.execute_reply.started": "2023-06-18T17:43:07.998503Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['month']==1].groupby('date_2').agg({'appliances':'mean'}).appliances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-17T09:14:35.672734Z",
     "iopub.status.busy": "2023-06-17T09:14:35.672359Z",
     "iopub.status.idle": "2023-06-17T09:14:35.68139Z",
     "shell.execute_reply": "2023-06-17T09:14:35.679635Z",
     "shell.execute_reply.started": "2023-06-17T09:14:35.672704Z"
    }
   },
   "source": [
    "**Inferences**\n",
    "1. **`rv1` and `rv2` features show no visible variance.** We'll verify their correlation strength against the target and make a retain/drop decision.\n",
    "2. **`lights` feature has largely zero valuess.** We'll verify their correlation strength against the target and make a retain/drop decision.\n",
    "3. **Temperature and Relative Humidity features'** histograms as captured by sensors 0-9 have **similar distributions.** From **psychrometric properties of ambient air,** relative humidity of air is defined for a given temperature. So it follows that, unless air is conditioned with humidity adjustments, **`t0-t9` and `rh_0-rh_9` should be pairwise correlated**.\n",
    "4. **Windspeed and relative humidity move in the opposite directions** and the same is observed in weather station **`windspeed`** and **`rh_out`** features.\n",
    "5. The day-wise consumption reveals some insights during winter and summer months of Jan and May. The transition spring months seems to see randm consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.2\"></a>\n",
    "## 3.2 Bivariate Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Daily consumption trendline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:43:20.413125Z",
     "iopub.status.busy": "2023-06-18T17:43:20.412662Z",
     "iopub.status.idle": "2023-06-18T17:43:24.698603Z",
     "shell.execute_reply": "2023-06-18T17:43:24.697660Z",
     "shell.execute_reply.started": "2023-06-18T17:43:20.413060Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "months = [1, 2, 3, 4, 5]\n",
    "m_names = ['January', 'February', 'March', 'April', 'May']\n",
    "subplots = [511, 512, 513, 514, 515]\n",
    "\n",
    "fig, axs = plt.subplots(len(months), 1, figsize=(15, 12))\n",
    "\n",
    "for i, (month, m_name) in enumerate(zip(months, m_names)):\n",
    "    ax = axs[i]\n",
    "    df_month = df[df['month'] == month]\n",
    "    sorted_dates = sorted(list(df_month['date_2'].unique()))\n",
    "\n",
    "    # Get the mean appliance values for the current month\n",
    "    y = df_month.groupby('date_2').agg({'appliances': 'mean'}).appliances.to_list()\n",
    "\n",
    "    ax.plot(sorted_dates, y, color='green', linewidth=1.7)\n",
    "    ax.set_title(m_name)\n",
    "\n",
    "    # Set the x-axis tick positions and labels\n",
    "    day_of_week_labels = [date.strftime('%a') for date in sorted_dates]\n",
    "    day_of_month_labels = [date.day for date in sorted_dates] \n",
    "    \n",
    "    x_labels = \\\n",
    "    [f'{dow}\\n{dom}' for dow, dom in zip(day_of_week_labels, day_of_month_labels)]  \n",
    "    # Concatenate labels\n",
    "\n",
    "    ax.set_xticks(sorted_dates)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.suptitle('Daily Mean Log Appliance Power Consumption')\n",
    "fig.text(0, 0.5, 'Appliance Energy Consumption', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0, 'Day of the month', ha='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Daily Mean Log Appliance Power Consumption.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily Consumption trends:\n",
    "* Onset of the weekend: Upward trend in energy consumption\n",
    "* Consistent downward trend in consumption levels at start of the week (pivot points highlighted in blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:43:32.519348Z",
     "iopub.status.busy": "2023-06-18T17:43:32.518553Z",
     "iopub.status.idle": "2023-06-18T17:43:32.601552Z",
     "shell.execute_reply": "2023-06-18T17:43:32.599706Z",
     "shell.execute_reply.started": "2023-06-18T17:43:32.519301Z"
    }
   },
   "outputs": [],
   "source": [
    "df['hour'] = pd.to_datetime(df['date']).dt.strftime('%H').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:43:36.667289Z",
     "iopub.status.busy": "2023-06-18T17:43:36.666804Z",
     "iopub.status.idle": "2023-06-18T17:43:37.608029Z",
     "shell.execute_reply": "2023-06-18T17:43:37.606917Z",
     "shell.execute_reply.started": "2023-06-18T17:43:36.667250Z"
    }
   },
   "outputs": [],
   "source": [
    "WeekendDf = df[df.day_type == '1'].groupby('hour')['appliances'].median().reset_index()\n",
    "WeekdayDf = df[df.day_type == '0'].groupby('hour')['appliances'].median().reset_index()\n",
    "\n",
    "\n",
    "WeekendDf['appliances'] = np.exp(WeekendDf['appliances'])\n",
    "WeekdayDf['appliances'] = np.exp(WeekdayDf['appliances'])\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "x = np.arange(len(WeekendDf['hour']))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 4))\n",
    "\n",
    "ax.bar(x - bar_width/2, WeekendDf['appliances'], bar_width, label='Weekend')\n",
    "\n",
    "ax.bar(x + bar_width/2, WeekdayDf['appliances'], bar_width, label='Weekday')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(WeekendDf['hour'])\n",
    "\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('Appliances')\n",
    "ax.set_title('Hourly Trends')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.savefig(f'Weekend-vc-Weekday-hourly-trends.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekday vs Weekend Hourly Energy Consumption: Inferences\n",
    "* Uptick in Energy consumption levels between 8AM to 9PM\n",
    "* Peak Energy Consumption between the hours 5PM and 9PM\n",
    "* Weekend daytime energy consumption is greater than that during weekdays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ambient Morning Temperature (tout) tredline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:43:42.958468Z",
     "iopub.status.busy": "2023-06-18T17:43:42.956921Z",
     "iopub.status.idle": "2023-06-18T17:43:42.965540Z",
     "shell.execute_reply": "2023-06-18T17:43:42.964321Z",
     "shell.execute_reply.started": "2023-06-18T17:43:42.958421Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr_map(df, title, method='spearman', numeric_only = True, tick_size = 10, annot_size=8, annot_kws=8):\n",
    "    mask = np.triu(np.ones_like(df.corr(numeric_only=numeric_only), dtype=bool))\n",
    "    heatmap = sns.heatmap(df.corr(method=method, numeric_only = numeric_only), fmt = '.2f',  annot = True, annot_kws = {'size': annot_kws}, mask=mask, cmap='BrBG')#\n",
    "    plt.xticks(rotation=80, fontsize= tick_size)\n",
    "    plt.yticks( fontsize= tick_size)\n",
    "\n",
    "    heatmap.set_title(title, fontdict={'fontsize':annot_size}, pad=12)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:43:45.271656Z",
     "iopub.status.busy": "2023-06-18T17:43:45.270745Z",
     "iopub.status.idle": "2023-06-18T17:43:45.278592Z",
     "shell.execute_reply": "2023-06-18T17:43:45.277193Z",
     "shell.execute_reply.started": "2023-06-18T17:43:45.271608Z"
    }
   },
   "outputs": [],
   "source": [
    "df['inv_log_appliance'] = np.exp(df['appliances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:43:48.732024Z",
     "iopub.status.busy": "2023-06-18T17:43:48.731617Z",
     "iopub.status.idle": "2023-06-18T17:43:48.742755Z",
     "shell.execute_reply": "2023-06-18T17:43:48.741007Z",
     "shell.execute_reply.started": "2023-06-18T17:43:48.731990Z"
    }
   },
   "outputs": [],
   "source": [
    "df['appliances'].max(), df['inv_log_appliance'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:43:50.618720Z",
     "iopub.status.busy": "2023-06-18T17:43:50.618248Z",
     "iopub.status.idle": "2023-06-18T17:43:53.082529Z",
     "shell.execute_reply": "2023-06-18T17:43:53.081582Z",
     "shell.execute_reply.started": "2023-06-18T17:43:50.618686Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_map(df.drop(['month', 'date_2', 'time','rv1','rv2','visibility', 'windspeed',\n",
    "       'week','day_num', 'day_type', 'week_num'], axis =1), method='pearson' , title='Feature Correlations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.3\"></a>\n",
    "## 3.3 Multivariate Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:44:37.201636Z",
     "iopub.status.busy": "2023-06-18T17:44:37.200818Z",
     "iopub.status.idle": "2023-06-18T17:44:38.348606Z",
     "shell.execute_reply": "2023-06-18T17:44:38.347289Z",
     "shell.execute_reply.started": "2023-06-18T17:44:37.201594Z"
    }
   },
   "outputs": [],
   "source": [
    "df['temprature_inside'] = df[['t1', 't2', 't3', 't4', 't5', 't7', 't8', 't9']].mean(axis=1)\n",
    "df['temprature_outside'] = df['t6']\n",
    "\n",
    "df['inv_log_appliances'] = np.exp(df['appliances']) - 30\n",
    "\n",
    "MultvariateDF = df[['week_num', 'temprature_inside', 'temprature_outside', 'windspeed', 'inv_log_appliances']].groupby('week_num')[['temprature_inside', 'temprature_outside', 'windspeed', 'inv_log_appliances']].median().reset_index()\n",
    "MultvariateDF['windspeed'] = MultvariateDF['windspeed'] * 6 +10\n",
    "\n",
    "bar_width = 0.35\n",
    "bar_offset = bar_width / 2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8)) \n",
    "\n",
    "plt.bar(MultvariateDF['week_num'], MultvariateDF['temprature_inside'], width=bar_width, align='center', label='temprature Inside')\n",
    "\n",
    "plt.bar(np.array(MultvariateDF['week_num']) + bar_offset, MultvariateDF['temprature_outside'], width=bar_width, align='center', label='temprature Outside')\n",
    "\n",
    "\n",
    "plt.plot(MultvariateDF['week_num'], MultvariateDF['windspeed'], label='Wind Speed', c = 'black', linestyle = 'dashed')\n",
    "\n",
    "plt.plot(MultvariateDF['week_num'], MultvariateDF['inv_log_appliances'], label='Inv Log Appliances', linestyle = 'dotted')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Week Number')\n",
    "plt.ylabel('')\n",
    "plt.title('Appliances trends with temprature Inside and Outside')\n",
    "plt.xticks(MultvariateDF['week_num'])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'Appliances-trends-with-temprature-Inside-and-Outside.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:44:42.646131Z",
     "iopub.status.busy": "2023-06-18T17:44:42.645662Z",
     "iopub.status.idle": "2023-06-18T17:44:43.746419Z",
     "shell.execute_reply": "2023-06-18T17:44:43.745219Z",
     "shell.execute_reply.started": "2023-06-18T17:44:42.646077Z"
    }
   },
   "outputs": [],
   "source": [
    "df['humidity_inside'] = df[['rh_1', 'rh_2', 'rh_3', 'rh_4', 'rh_5', 'rh_7', 'rh_8', 'rh_9']].mean(axis=1)\n",
    "df['humidity_outside'] = df['rh_6']\n",
    "\n",
    "df['inv_log_appliances'] = np.exp(df['appliances']) - 30\n",
    "\n",
    "MultvariateDF = df[['week_num', 'humidity_inside', 'humidity_outside', 'windspeed', 'inv_log_appliances']].groupby('week_num')[['humidity_inside', 'humidity_outside', 'windspeed', 'inv_log_appliances']].median().reset_index()\n",
    "MultvariateDF['windspeed'] = MultvariateDF['windspeed'] * 6 +10\n",
    "\n",
    "bar_width = 0.35\n",
    "bar_offset = bar_width / 2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8)) \n",
    "\n",
    "plt.bar(MultvariateDF['week_num'], MultvariateDF['humidity_inside'], width=bar_width, align='center', label='Humidity Inside')\n",
    "\n",
    "plt.bar(np.array(MultvariateDF['week_num']) + bar_offset, MultvariateDF['humidity_outside'], width=bar_width, align='center', label='Humidity Outside')\n",
    "\n",
    "\n",
    "plt.plot(MultvariateDF['week_num'], MultvariateDF['windspeed'], label='Wind Speed', c = 'black', linestyle = 'dashed')\n",
    "\n",
    "plt.plot(MultvariateDF['week_num'], MultvariateDF['inv_log_appliances'], label='Log Inv Appliances', linestyle = 'dotted')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Week Number')\n",
    "plt.ylabel('')\n",
    "plt.title('Appliances trends with Humidity Inside and Outside')\n",
    "plt.xticks(MultvariateDF['week_num'])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f'Appliances-trends-with-humidity-Inside-and-Outside.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is a **significant difference in mean inside temperature and outside temperature,** which suggests that the space is being **artificially heated.** This also follows our initial hypothesis from the weak correlation between internal temperature and internal humidity.\n",
    "* We also observe that the **inverse log transformed target (appliance power usage at actuals) sharply follows the mean internal temperature changes.** This suggests that **internal  heating is a significant driver of household energy consumption.** We can save on consumption, if we use \n",
    "    - Energy efficient heating system\n",
    "    - Better insulation \n",
    "    - Fixing air leakages from the interiors to the exteriors of the house"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.4\"></a>\n",
    "## 3.4 Summary Observations and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "Temperature columns - Temperature inside the house varies between 14.89 Deg & 29.85 Deg , temperatire outside (T6) varies between -6.06 Deg to 28.29 Deg . The reason for this variation is sensors are kept outside the house\n",
    "\n",
    "**Humidiy columns** - Humidity inside house varies is between 20.60% to 63.36% with exception of RH_5 (Bathroom) and RH_6 (Outside house) which varies between 29.82% to 96.32% and 1% to 99.9% respectively.\n",
    "\n",
    "**Appliances** - 75% of Appliance consumption is less than 100 Wh . With the maximum consumption of 1080 Wh (inverse log transformed target) , there will be outliers in this column and there are small number of cases where consumption is very high\n",
    "\n",
    "**Lights column** - Intially we believed lights column will be able to give useful information . With 11438 0 (zero) enteries in 14801 rows , this column will not add any value to the model . We believed light consumption along with humidity level in a room will give idea about human presence in the room and hence its impact on Appliance consumption. Hence, we will dropping this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "# 4. Model Training, Hyperparameter tuning, Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:44:54.330944Z",
     "iopub.status.busy": "2023-06-18T17:44:54.330392Z",
     "iopub.status.idle": "2023-06-18T17:44:54.510511Z",
     "shell.execute_reply": "2023-06-18T17:44:54.509159Z",
     "shell.execute_reply.started": "2023-06-18T17:44:54.330903Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection, metrics\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import time\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:44:57.971212Z",
     "iopub.status.busy": "2023-06-18T17:44:57.970740Z",
     "iopub.status.idle": "2023-06-18T17:44:57.988267Z",
     "shell.execute_reply": "2023-06-18T17:44:57.986694Z",
     "shell.execute_reply.started": "2023-06-18T17:44:57.971177Z"
    }
   },
   "outputs": [],
   "source": [
    "# 75% of the data is usedfor the training of the models and the rest is used for testing\n",
    "train, test = train_test_split(df,test_size=0.25,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:44:59.760992Z",
     "iopub.status.busy": "2023-06-18T17:44:59.760516Z",
     "iopub.status.idle": "2023-06-18T17:44:59.767380Z",
     "shell.execute_reply": "2023-06-18T17:44:59.766069Z",
     "shell.execute_reply.started": "2023-06-18T17:44:59.760952Z"
    }
   },
   "outputs": [],
   "source": [
    "# These features will be used to select the model, as it has train and test  split is available\n",
    "feature_vars = col_temp + col_hum + col_weather +   col_time\n",
    "target_vars = col_target\n",
    "\n",
    "\n",
    "# We use below features after selecting the final model\n",
    "model_features_vars = col_temp + col_hum + col_weather +  col_time\n",
    "model_target_vars = col_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:45:02.700362Z",
     "iopub.status.busy": "2023-06-18T17:45:02.699859Z",
     "iopub.status.idle": "2023-06-18T17:45:02.716518Z",
     "shell.execute_reply": "2023-06-18T17:45:02.714691Z",
     "shell.execute_reply.started": "2023-06-18T17:45:02.700323Z"
    }
   },
   "outputs": [],
   "source": [
    "#Split training dataset into independent and dependent varibales\n",
    "train_X = train[feature_vars]\n",
    "train_y = train[target_vars]\n",
    "\n",
    "#Split testing dataset into independent and dependent varibales\n",
    "test_X = test[feature_vars]\n",
    "test_y = test[target_vars]\n",
    "\n",
    "# We use below features after selecting the final model\n",
    "model_train_X = train[feature_vars]\n",
    "model_train_y = train[target_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:45:05.760893Z",
     "iopub.status.busy": "2023-06-18T17:45:05.760404Z",
     "iopub.status.idle": "2023-06-18T17:45:05.769500Z",
     "shell.execute_reply": "2023-06-18T17:45:05.767976Z",
     "shell.execute_reply.started": "2023-06-18T17:45:05.760858Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "           ['Lasso', Lasso()],\n",
    "           ['Ridge', Ridge()],\n",
    "           ['K-Neighbors Regressor',  neighbors.KNeighborsRegressor()],\n",
    "           ['SVR' , SVR(kernel='rbf')],\n",
    "           ['Random Forest',RandomForestRegressor()],\n",
    "           ['Extra Tree Regressor',ExtraTreesRegressor()],\n",
    "           ['Gradient Boosting Classifier', GradientBoostingRegressor()] ,\n",
    "           ['XGB Regressor', xgb.XGBRegressor()] ,\n",
    "           ['MLP Regressor', MLPRegressor(  activation='relu', solver='adam',learning_rate='adaptive',max_iter=1000,learning_rate_init=0.01,alpha=0.01)]\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:45:09.152556Z",
     "iopub.status.busy": "2023-06-18T17:45:09.152080Z",
     "iopub.status.idle": "2023-06-18T17:46:15.259929Z",
     "shell.execute_reply": "2023-06-18T17:46:15.258367Z",
     "shell.execute_reply.started": "2023-06-18T17:45:09.152521Z"
    }
   },
   "outputs": [],
   "source": [
    "model_data = []\n",
    "for name,curr_model in models :\n",
    "    curr_model_data = {}\n",
    "    curr_model.random_state = 78\n",
    "    curr_model_data[\"Name\"] = name\n",
    "    start = time.time()\n",
    "    curr_model.fit(train_X,train_y)\n",
    "    end = time.time()\n",
    "    curr_model_data[\"Train_Time\"] = end - start\n",
    "    curr_model_data[\"Train R2 Score\"] = metrics.r2_score(train_y,curr_model.predict(train_X))\n",
    "    curr_model_data[\"Validate R2 Score\"] = metrics.r2_score(test_y,curr_model.predict(test_X))\n",
    "    curr_model_data[\"Test RMSE Score\"] = sqrt(mean_squared_error(test_y,curr_model.predict(test_X)))\n",
    "    model_data.append(curr_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:46:20.749110Z",
     "iopub.status.busy": "2023-06-18T17:46:20.748472Z",
     "iopub.status.idle": "2023-06-18T17:46:20.770577Z",
     "shell.execute_reply": "2023-06-18T17:46:20.769111Z",
     "shell.execute_reply.started": "2023-06-18T17:46:20.749040Z"
    }
   },
   "outputs": [],
   "source": [
    "modelComparison = pd.DataFrame(model_data)\n",
    "modelComparison = modelComparison.sort_values(by=['Train R2 Score', 'Validate R2 Score', 'Test RMSE Score']).reset_index()\n",
    "modelComparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:47:45.255272Z",
     "iopub.status.busy": "2023-06-18T17:47:45.254789Z",
     "iopub.status.idle": "2023-06-18T17:47:45.263101Z",
     "shell.execute_reply": "2023-06-18T17:47:45.261788Z",
     "shell.execute_reply.started": "2023-06-18T17:47:45.255238Z"
    }
   },
   "outputs": [],
   "source": [
    "modelComparison.set_index('Name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:47:56.079971Z",
     "iopub.status.busy": "2023-06-18T17:47:56.079494Z",
     "iopub.status.idle": "2023-06-18T17:47:56.799334Z",
     "shell.execute_reply": "2023-06-18T17:47:56.798056Z",
     "shell.execute_reply.started": "2023-06-18T17:47:56.079937Z"
    }
   },
   "outputs": [],
   "source": [
    "modelComparison[modelComparison['Train R2 Score'] > 0][['Train R2 Score', 'Validate R2 Score']].plot.bar()\n",
    "\n",
    "# plt.figure(figsize = (8, 4))\n",
    "plt.xlabel('')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel('')\n",
    "plt.title('Models Comparision')\n",
    "\n",
    "plt.savefig(f'Models-comparision.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By comparing all the model, found `Extra Tree Regressor` giving best results. \n",
    "* Further, we will implement hyperparameters tunning on `Extra Tree Regressor`\n",
    "* Below are the best features, observed for `Extra Tree Regressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:49:56.410219Z",
     "iopub.status.busy": "2023-06-18T17:49:56.409742Z",
     "iopub.status.idle": "2023-06-18T17:50:00.100057Z",
     "shell.execute_reply": "2023-06-18T17:50:00.098776Z",
     "shell.execute_reply.started": "2023-06-18T17:49:56.410187Z"
    }
   },
   "outputs": [],
   "source": [
    "xtr = ExtraTreesRegressor(criterion='poisson',max_depth=100,max_features='log2', n_estimators=350,n_jobs=-1,random_state=40)\n",
    "xtr.fit(model_train_X,model_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:50:08.032356Z",
     "iopub.status.busy": "2023-06-18T17:50:08.031896Z",
     "iopub.status.idle": "2023-06-18T17:50:08.321214Z",
     "shell.execute_reply": "2023-06-18T17:50:08.320208Z",
     "shell.execute_reply.started": "2023-06-18T17:50:08.032325Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.r2_score(test_y,xtr.predict(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the test Data for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:52:48.483618Z",
     "iopub.status.busy": "2023-06-18T17:52:48.483178Z",
     "iopub.status.idle": "2023-06-18T17:52:48.496302Z",
     "shell.execute_reply": "2023-06-18T17:52:48.494922Z",
     "shell.execute_reply.started": "2023-06-18T17:52:48.483585Z"
    }
   },
   "outputs": [],
   "source": [
    "df_t[\"hour\"] = pd.to_datetime(df_t[\"date\"]).dt.hour\n",
    "df_t[\"weekday\"] = pd.to_datetime(df_t[\"date\"]).dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:53:11.672967Z",
     "iopub.status.busy": "2023-06-18T17:53:11.671919Z",
     "iopub.status.idle": "2023-06-18T17:53:11.683165Z",
     "shell.execute_reply": "2023-06-18T17:53:11.682130Z",
     "shell.execute_reply.started": "2023-06-18T17:53:11.672910Z"
    }
   },
   "outputs": [],
   "source": [
    "ids = list(df_t['ID'])\n",
    "model_test_X = df_t[col_temp + col_hum + col_weather + col_time ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:54:05.146816Z",
     "iopub.status.busy": "2023-06-18T17:54:05.146189Z",
     "iopub.status.idle": "2023-06-18T17:54:05.423574Z",
     "shell.execute_reply": "2023-06-18T17:54:05.422398Z",
     "shell.execute_reply.started": "2023-06-18T17:54:05.146771Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = xtr.predict(model_test_X)\n",
    "sub_xtree = pd.DataFrame({\"ID\": ids, \"appliances\":list(pred)})\n",
    "sub_xtree.to_csv(\"/kaggle/working/sub_xtree.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-18T17:54:19.344760Z",
     "iopub.status.busy": "2023-06-18T17:54:19.343885Z",
     "iopub.status.idle": "2023-06-18T17:54:19.358727Z",
     "shell.execute_reply": "2023-06-18T17:54:19.357157Z",
     "shell.execute_reply.started": "2023-06-18T17:54:19.344707Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_xtree.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Achieved accuracy : 78.45 %**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
